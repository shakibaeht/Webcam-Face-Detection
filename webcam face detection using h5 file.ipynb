{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dadd42af-b2c2-4a67-bd8b-ed310861baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68d5825e-10c1-4e0d-afcb-169b8ed23c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('C:/Users/sabaa/My Jupyter/complete model/63.h5',compile=False)\n",
    "#model = keras.models.load_model('C:/Users/sabaa/My Jupyter/complete model/model-3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcdde4d9-41ed-4c03-93d3-cb6fb15a22e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only compile the model if simple loading will get you error\n",
    "#model.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(1e-3))\n",
    "#model.compile(loss='mae', optimizer=keras.optimizers.Adam(1e-3))\n",
    "model.compile(optimizer='adam', loss='mae', metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eab5c8ba-b524-4136-b019-76433c8b0ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the desired input shape for your model\n",
    "model_input_width, model_input_height, channels = 80, 60, 3\n",
    "\n",
    "# Set the desired size for the displayed webcam image\n",
    "display_width, display_height = 640, 480\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Set the desired frame rate (fps)\n",
    "target_fps = 30\n",
    "delay = 1 / target_fps\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Resize the frame to the desired display size\n",
    "    display_frame = cv2.resize(frame, (display_width, display_height))\n",
    "\n",
    "    # Resize the frame to the desired input shape for the model\n",
    "    model_input_frame = cv2.resize(frame, (model_input_width, model_input_height))\n",
    "\n",
    "    # Preprocess the frame for the facial landmark recognition model\n",
    "    # You may need to adjust the preprocessing steps based on your model\n",
    "    # For example, normalizing pixel values to the range [0, 1]\n",
    "    face = model_input_frame / 255.0  # Assuming pixel values are in the range [0, 255]\n",
    "    face = np.expand_dims(face, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform facial landmark recognition\n",
    "    landmarks = model.predict(face)\n",
    "    # this function get the image and landmarks and returns the image with landmarks on it\n",
    "    def plot_lankmarks(image, landmarks):\n",
    "        h, w, _ = image.shape\n",
    "        radius = int(h * 0.005) # this is the thickness of the dots in the picture\n",
    "    \n",
    "        # We go through the pictures and put the dots in the positions in that picture\n",
    "        for i in range(0, len(landmarks), 2):\n",
    "            x = int(landmarks[i] * w)\n",
    "            y = int(landmarks[i+1] * h)\n",
    "    \n",
    "            image = cv2.circle(image, (x, y), radius, (255, 0, 0), -1)\n",
    "\n",
    "    # Draw landmarks on the display frame\n",
    "    for i in range(len(landmarks[0]) // 2):\n",
    "        x_lm = int(landmarks[0][2*i] * display_width)\n",
    "        y_lm = int(landmarks[0][2*i + 1] * display_height)\n",
    "        cv2.circle(display_frame, (x_lm, y_lm), 2, (0, 255, 0), -1)\n",
    "\n",
    "    # Display the frame with landmarks\n",
    "    cv2.imshow('Facial Landmark Recognition', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed or after 15 seconds\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') or (time.time() - start_time) > 30:\n",
    "        break\n",
    "\n",
    "    # Add a delay to achieve the target frame rate\n",
    "    #time.sleep(delay)\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0279e8e-e149-4db9-ab45-5658735ac87e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m face \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(face, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Perform facial landmark recognition\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m landmarks \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(face)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Draw landmarks on the display frame and connect them to form a circle\u001b[39;00m\n\u001b[0;32m     37\u001b[0m num_landmarks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(landmarks[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Set the desired input shape for your model\n",
    "model_input_width, model_input_height, channels = 80, 60, 3\n",
    "\n",
    "# Set the desired size for the displayed webcam image\n",
    "display_width, display_height = 640, 480\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Get the start time\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Resize the frame to the desired display size\n",
    "    display_frame = cv2.resize(frame, (display_width, display_height))\n",
    "\n",
    "    # Resize the frame to the desired input shape for the model\n",
    "    model_input_frame = cv2.resize(frame, (model_input_width, model_input_height))\n",
    "\n",
    "    # Preprocess the frame for the facial landmark recognition model\n",
    "    # You may need to adjust the preprocessing steps based on your model\n",
    "    # For example, normalizing pixel values to the range [0, 1]\n",
    "    face = model_input_frame / 255.0  # Assuming pixel values are in the range [0, 255]\n",
    "    face = np.expand_dims(face, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform facial landmark recognition\n",
    "    landmarks = model.predict(face)\n",
    "\n",
    "    # Draw landmarks on the display frame and connect them to form a circle\n",
    "    num_landmarks = len(landmarks[0]) // 2\n",
    "    for i in range(num_landmarks):\n",
    "        x_lm = int(landmarks[0][2*i] * display_width)\n",
    "        y_lm = int(landmarks[0][2*i + 1] * display_height)\n",
    "        cv2.circle(display_frame, (x_lm, y_lm), 2, (0, 255, 0), -1)\n",
    "\n",
    "        # Connect landmarks to form a circle\n",
    "        next_index = (i + 1) % num_landmarks\n",
    "        x_next = int(landmarks[0][2*next_index] * display_width)\n",
    "        y_next = int(landmarks[0][2*next_index + 1] * display_height)\n",
    "        cv2.line(display_frame, (x_lm, y_lm), (x_next, y_next), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with landmarks and circle\n",
    "    cv2.imshow('Facial Landmark Recognition', display_frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed or after 15 seconds\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') or (time.time() - start_time) > 15:\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
